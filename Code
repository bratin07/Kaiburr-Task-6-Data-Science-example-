from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
In [3]:
linkcode
df_full = pd.read_csv('../input/consumercomplaintsdata/Consumer_Complaints.csv')
df_full.head()
# How many unique financial products (the second column) are we talking about here
df_full['Product'].nunique()
# The shape of the full, unmodified data
print('Shape of data',df_full.shape)
# The idea is to demonstrate a workflow, so we will work with a smaller portion of the data

# First, we retain only the columns relevant to our present purpose

df=df_full[['Consumer complaint narrative','Product']]
print('Shape of data',df.shape)
Shape of data (903983, 2)
# Next, we get rid of nulls
print('Before dropping the nulls')
display('Null count', df.isna().sum())
print('Total rows of data', len(df))
df.dropna(inplace=True)
print('='*80)
print('After dropping the nulls')
display('Null count', df.isna().sum())
print('Total rows of data', len(df))
df=df.head(1000).reset_index(drop=True)
display(df.head())
display(df.tail())
print('Shape of data',df.shape)
Shape of data (1000, 2)
df.tail()
# Kinds of products on which complaints are generated
df['Product'].nunique()
df['Consumer complaint narrative'][0]
#Categories of products - the classes for which we will predict

list(df.Product.unique())
df['Product'].value_counts()
#Train-test split
25% of the total data is used as validation data while the remaining as training.
X_train, X_test, y_train, y_test = train_test_split(
                                            df['Consumer complaint narrative'], df['Product'], 
                                            test_size=0.25, random_state=0, stratify=df['Product'])
print(f'Training utterances: {len(X_train)} of shape {X_train.shape}')
print(f'Validation utterances: {len(X_test)} of shape {X_test.shape}')

# NOTE: The features occupy a single column
Training utterances: 750 of shape (750,)
Validation utterances: 250 of shape (250,)
display(y_train.value_counts())
display(y_test.value_counts())
#Calculating tf-idf scores
#Calculating tf-idf scores for each unique token in the dataset and creating frequency chart for #each utterance in the dataset.
In [18]:
#linkcode
# instantiate the vectorizer object
vectorizer = TfidfVectorizer(stop_words= 'english')
# convert the documents into a matrix
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec  = vectorizer.transform(X_test)
X_train_vec, X_test_vec

#Feature Selection
#SelectKBest Select features according to the k highest scores.
#Chi-square test measures dependence between stochastic variables, so using this function #“weeds out” the features that are the most likely to be independent of class and therefore #irrelevant for classification.
from sklearn.feature_selection import SelectKBest, chi2

n_features=100

ch2 = SelectKBest(chi2, k=n_features)
X_train_sp = ch2.fit_transform(X_train_vec, y_train)
X_test_sp  = ch2.transform(X_test_vec)

X_train_sp, X_test_sp
# Converting the sparse matrix to a dense one to visualize it.

cols = list(range(n_features))

X_train_dense = pd.DataFrame(data=X_train_sp.toarray(), columns=cols)
X_test_dense  = pd.DataFrame(data=X_test_sp.toarray(), columns=cols)
print(X_train_dense.shape, X_test_dense.shape)
X_train_dense
# Now we have train and test data as vectors
# Let us also convert the target data appropriately

 
encoder = LabelEncoder()
y_train_num  = encoder.fit_transform(y_train)
y_test_num   = encoder.transform(y_test)
y_train_num.min(), y_train_num.max(), y_test_num.min(), y_test_num.max() # sanity check
# What does the target look like, after encoding. Check out the first n datapoints
n=5
print('Text   Encoding')
print('-'*50)
for p,q in zip(y_train[:n].values,y_train_num):
    print(f'{q}      {p}')
# Now, if you are fussy and want to see exactly what kind of encoding has happened.
mapping = {l: i for i, l in enumerate(encoder.classes_)}
mapping
#Our data is ready for modelling
#We want to train a model such that looking at the complaint text, it should be able to determine #which category of complaint it deals with.
#linkcode
rf_model  = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs = -1)
scores = cross_val_score(rf_model,
                         X_train_dense,
                         y_train_num,
                         cv=5,
                         n_jobs = -1,
                         scoring = 'accuracy')
scores.mean()

rf_model.fit(X_train_dense, y_train_num)
preds=rf_model.predict(X_test_dense)
print('Predictions ready')
#Predictions ready
#linkcode
# What does a prediction look like - let's take the first one
preds[0]
# Let's revert back to the categories we understand
preds=encoder.inverse_transform(preds)
preds[0]
Out[27]:
#brief look at the predictions made
In [28]:
linkcode
report = pd.DataFrame(columns=['Complaint','Actual Product','Prediction'])
report['Complaint']      = X_test
report['Actual Product'] = y_test 
report['Prediction']     = preds
report
## How accurate is this model?
report['Correct'] = (report['Actual Product'] == report['Prediction']).astype('int')
display(report)
print(f'Accuracy: {100*report.Correct.sum()/report.Correct.count()} %')
# Another way to crunch numbers
r = pd.DataFrame()
r['Correctly Predicted'] = report.groupby('Actual Product').sum()['Correct']
r['Overall Predicted']   = report.groupby('Prediction').count()['Correct']
r['Actuals']             = report.groupby('Actual Product').count()['Correct']
r
# brief look at a confusion matrix
In [32]:
linkcode
from sklearn.metrics import confusion_matrix
def plot_confusion_matrix(cm,labels,size=10, rotate_labels=False):
    '''
    This function receives a confusion matrix object and plots it out using seaborn
    '''
    import seaborn as sns
    import matplotlib.pyplot as plt
    font_specs = {"size": 20, 'fontweight':'bold'}
    title_specs= {"size": 16, 'fontweight':'bold'}
    figsize = size
    fig, ax = plt.subplots(figsize = (figsize,figsize), facecolor = '#ebebeb', frameon = True, edgecolor = 'black')
    ax = sns.heatmap(cm,annot=True, cbar = False, cmap = 'Blues',linewidths=5,
                  linecolor='#ebebeb', annot_kws=font_specs, fmt='g')

plt.xlabel('Predicted', fontdict = font_specs, labelpad=-(figsize*65))
    plt.ylabel('Actual', fontdict = font_specs, labelpad=15)
    ax.xaxis.set_ticklabels(labels)
    ax.yaxis.set_ticklabels(labels)
    if rotate_labels:
        ax.set_xticklabels(labels, rotation=90, ha='center')    
        ax.set_yticklabels(labels, rotation=0, ha='right')    
    
    ax.tick_params(labelbottom=False, labeltop=True, labelsize = 12, colors ='#151736' )
    plt.title('CONFUSION MATRIX',loc = 'right', pad = figsize*4 , fontdict = title_specs)
    plt.show()
print('custom function defined')    
custom function defined
cm = confusion_matrix(y_test, preds, labels=encoder.classes_)
plot_confusion_matrix(cm=cm,labels=encoder.classes_, size=12, rotate_labels=True)


